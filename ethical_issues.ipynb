{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:fill;\n",
    "           background-color:#BCEFC6;\n",
    "           letter-spacing:0.5px;border-bottom: 2px solid black;\">\n",
    "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/426827/812605/719b66b4a3afd1da8c107b026c66fa91/dataset-cover.jpg?t=2019-11-28-02-30-42\">\n",
    "    \n",
    "<H1 style=\"padding: 20px; color:black; font-weight:600;font-family: 'Garamond', 'Lucida Sans', sans-serif; text-align: center; font-size: 36px;\">Credit Card Approval Prediction - Ethics issues checklist</H1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #BCEFC6; padding: 20px; border-radius: 70px; border: 2px solid black;\">\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: center; color: black; font-weight: bold; font-size: 42px;\">\n",
    "    Questions\n",
    "    </h1>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 36px;\">\n",
    "   1. Does this activity involve the development, deployment and/or use of Artificial Intelligence-based systems?\n",
    "    </h1>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the chosen model is the Random Forest classifier.\n",
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 20px;\">\n",
    "    1) Explanation as to how the participants and/or end-users will be informed about:\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "- their interaction with an AI system/technology (if relevant);\n",
    "\n",
    "    - Transparency: Participants and end-users should be informed that they are interacting with an AI system.\n",
    "    - Education: Provide basic information about how the AI system works.\n",
    "\n",
    "- the abilities, limitations, risks and benefits of the proposed AI system/technique;\n",
    "\n",
    "    - Explain what the AI system can do\n",
    "    - Highlight specific strengths (e.g., accuracy, efficiency) relevant to the context ( credit card loan prediction).\n",
    "    - Discuss any limitations (e.g., lack of interpretability, resource-intensive training) to set realistic expectations\n",
    "    - Address potential scenarios where the AI system might fail.\n",
    "    - Mention the possibility of bias, fairness issues, and privacy concerns.\n",
    "    - Explain that overfitting can occur if not properly managed.\n",
    "    - Relate benefits to the specific use case\n",
    "\n",
    "- the manner in which decisions are taken and the logic behind them (if relevant) [LIME and SHAP methods, tree.txt]\n",
    "\n",
    "    - provide an overview of the model (Random Forest) used.\n",
    "    - Explain how the model combines multiple decision trees.\n",
    "    - Describe how the model assigns importance to different features.\n",
    "    - Explain which features contribute most to predictions.\n",
    "    - Explain how the AI system determines whether a loan is approved or denied.\n",
    "\n",
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 20px;\">\n",
    "    2)  Details on the measures taken to avoid bias in input data and algorithm design:\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "- Ensure the data used for training machine learning models is representative of all the demographics the system will serve.\n",
    "- Collect data from diverse sources and ensure it covers various groups (e.g., age, gender, ethnicity) to avoid underrepresentation.\n",
    "- Regularly test and review AI systems for potential bias and fairness.\n",
    "- Explain the features used, the model architecture, and any preprocessing steps applied to the data.\n",
    "- Handle missing data appropriately\n",
    "- Normalize features to prevent certain attributes from dominating the model. (like StandardScaler)\n",
    "- Remove irrelevant features that may introduce bias. (like FLAG_MOBIL)\n",
    "\n",
    "\n",
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 20px;\">\n",
    "    3) Explanation as to how the respect to fundamental human rights and freedoms (e.g. human autonomy, privacy and data protection) will be ensured:\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "- Ensure users understand their autonomy in accepting or rejecting AI-generated recommendations.\n",
    "- Explain how personal data is handled and protected.\n",
    "    - Organizations must handle personal data responsibly.\n",
    "    - Compliance with data protection laws (such as GDPR) ensures privacy rights are respected.\n",
    "    - Organizations should avoid deploying AI systems that violate human rights.\n",
    "\n",
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 20px;\">\n",
    "    4) Detailed explanation on the potential ethics risks and the risk mitigation measures\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "- Bias and Fairness:\n",
    "    - Risk: Random Forests can perpetuate biases present in training data.\n",
    "    - Mitigation: Regularly audit model predictions for fairness. Use techniques like reweighting or adversarial training to reduce bias.\n",
    "- Privacy Risks:\n",
    "    - Risk: Leakage of sensitive information through model predictions.\n",
    "    - Mitigation: Anonymize data, limit access to predictions, and ensure compliance with privacy regulations.\n",
    "- Accuracy and Accountability:\n",
    "    - Risk: Incorrect predictions impacting individuals’ lives.\n",
    "    - Mitigation: Rigorous testing, validation, and continuous monitoring. Ensure a human-in-the-loop for critical decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 36px;\">\n",
    "   2. Could the AI based system/technique potentially stigmatise or discriminate against people?\n",
    "    </h1>\n",
    "</div>\n",
    "<hr>\n",
    "\n",
    "- Stigmatization and Discrimination:\n",
    "\n",
    "    - Random Forest classification model learn from historical data, which may contain biases. If the training data reflects        societal biases (e.g., gender), the model can perpetuate them. In this case, the chances of gender and age discrimination are quite high\n",
    "    - AI decisions (loan approvals) can disproportionately affect certain groups.\n",
    "    - AI systems may inadvertently label individuals based on their characteristics. Such labels can stigmatize people.\n",
    "        \n",
    "- Mitigation: \n",
    "\n",
    "    - Regularly audit models for bias. Use fairness metrics to identify disparities.\n",
    "    - Develop and follow ethical guidelines during system development.\n",
    "    - Ensure a human-in-the-loop to review critical decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 36px;\">\n",
    "   3. Does the AI system/technique interact, replace or influence human decision-making processes?\n",
    "    </h1>\n",
    "</div>\n",
    "<hr>\n",
    "\n",
    "- The AI system replace human decision-making processes by influencing loan approvals.\n",
    "- To ensure meaningful control, humans should have the ability to review, override, or modify AI decisions.\n",
    "- Set thresholds for critical decisions. If the AI system’s decision crosses a threshold, it triggers an alert for human review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "    <h1 style=\"font-family:  'Garamond', 'Lucida Sans', sans-serif; text-align: left; color: #578B61; font-weight: bold; font-size: 36px;\">\n",
    "   4.Does the AI system/technique have the potential to lead to negative social (e.g. on democracy, media, labour market, freedoms, educational choices, mass surveillance) and/or environmental impacts either through intended applications or plausible alternative uses?\n",
    "    </h1>\n",
    "</div>\n",
    "<hr>\n",
    "\n",
    "Justification for Developing/Using Credit Card Approval Technology:\n",
    "\n",
    "- Credit card approval technology automates the evaluation of credit card applications. \n",
    "- AI system analyze a wide range of data points to assess an applicant’s creditworthiness. This reduces the impact of human biases and errors, resulting in fairer evaluations\n",
    "\n",
    "Ethics Risks and Mitigation Measures:\n",
    "\n",
    "- Model performance may degrade over time -> Continuously monitor model accuracy.\n",
    "- Black-box models lack transparency. -> Provide explanations for model decisions.[LIME & SHAP]\n",
    "- Handling personal data can lead to privacy breaches. -> Anonymize data during processing and limit access to sensitive information.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
